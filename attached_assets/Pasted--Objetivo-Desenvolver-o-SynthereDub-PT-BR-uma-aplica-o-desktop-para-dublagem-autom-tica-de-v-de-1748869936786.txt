## Objetivo

Desenvolver o SynthereDub PT-BR, uma aplicação desktop para dublagem automática de vídeos do inglês para o português brasileiro, utilizando Rust e Tauri. A aplicação deve ter uma interface gráfica intuitiva em português brasileiro, similar à imagem de referência fornecida, e integrar APIs para transcrição, tradução e síntese de voz.

## Especificações Técnicas

### Tecnologias Principais
- **Backend**: Rust (para performance e eficiência)
- **Frontend**: HTML/CSS/JavaScript (para interface gráfica)
- **Framework**: Tauri (para integração desktop)
- **Processamento de Áudio/Vídeo**: ffmpeg
- **APIs**:
  - **Transcrição**: Hugging Face (Whisper) - Chave: `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`
  - **Tradução**: Gemini - Chave: `AIzaSyBlaM63VdIAua3P_kwyUpbMZAj9v2pWi7w`
  - **Síntese de Voz**: EDGE TTS (sem necessidade de chave)

### Requisitos de Interface
- Interface gráfica totalmente em português brasileiro
- Design similar à imagem de referência fornecida
- Layout responsivo e moderno
- Elementos principais:
  - Botão "Selecionar Vídeo" e exibição do caminho
  - Botão "Salvar Em" e exibição do caminho
  - Dropdown "Idioma Original" (fixo em inglês)
  - Dropdown "Traduzir para" (fixo em português brasileiro)
  - Seletor de vozes em português brasileiro:
    - pt-BR-AntonioNeural (masculina) - padrão
    - pt-BR-FranciscaNeural (feminina)
    - pt-BR-BrendaNeural (feminina)
    - pt-BR-HumbertoNeural (masculina)
  - Botão "Iniciar"
  - Barra de progresso e área de status

### Fluxo de Trabalho
1. Extração de áudio do vídeo original
2. Transcrição do áudio em inglês usando Hugging Face (Whisper)
3. Tradução do texto para português brasileiro usando Gemini
4. Síntese de voz em português usando EDGE TTS
5. Sincronização do áudio dublado com o vídeo original
6. Geração do vídeo dublado final

## Estrutura do Projeto

```
synthere_dub/
├── src/                    # Frontend (HTML, CSS, JavaScript)
│   ├── index.html          # Página principal da interface
│   ├── style.css           # Estilos da interface
│   └── main.js             # Lógica do frontend
├── src-tauri/              # Backend Rust e configuração Tauri
│   ├── src/                # Código Rust
│   │   ├── main.rs         # Ponto de entrada e lógica principal
│   │   └── lib.rs          # Funções auxiliares
│   ├── Cargo.toml          # Dependências Rust
│   └── tauri.conf.json     # Configuração do Tauri
├── vite.config.js          # Configuração do Vite
└── package.json            # Dependências JavaScript
```

## Implementação Detalhada

### 1. Configuração do Projeto Tauri

```bash
# Instalar dependências necessárias
apt-get update
apt-get install -y build-essential pkg-config libssl-dev libgtk-3-dev libwebkit2gtk-4.0-dev libappindicator3-dev librsvg2-dev patchelf ffmpeg

# Instalar Rust e Cargo
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
source "$HOME/.cargo/env"

# Criar projeto Tauri
mkdir -p synthere_dub
cd synthere_dub
npm init -y
npm install --save-dev vite
npm pkg set scripts.dev="vite" scripts.build="vite build"

# Configurar Tauri
cargo install tauri-cli
cargo tauri init
```

### 2. Interface Gráfica (Frontend)

#### HTML (index.html)
```html
<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SynthereDub PT-BR</title>
    <link rel="stylesheet" href="./style.css">
</head>
<body>
    <div class="container">
        <h1>SynthereDub PT-BR</h1>
        <div class="main-content">
            <div class="input-group">
                <label for="video-path">Vídeo Original:</label>
                <div class="file-input">
                    <button id="select-video-btn">Selecionar Vídeo</button>
                    <span id="selected-video-path">Nenhum vídeo selecionado</span>
                </div>
            </div>
            
            <div class="input-group">
                <label for="save-path">Salvar Em:</label>
                <div class="file-input">
                    <button id="save-to-btn">Escolher Local</button>
                    <span id="save-path">Local padrão</span>
                </div>
            </div>
            
            <div class="options-row">
                <div class="input-group">
                    <label for="original-language">Idioma Original:</label>
                    <select id="original-language">
                        <option value="en">Inglês</option>
                    </select>
                </div>
                
                <div class="input-group">
                    <label for="target-language">Traduzir para:</label>
                    <select id="target-language">
                        <option value="pt-BR">Português Brasileiro</option>
                    </select>
                </div>
            </div>
            
            <div class="options-row">
                <div class="input-group">
                    <label for="use-tts">Usar EDGE TTS:</label>
                    <div class="checkbox-wrapper">
                        <input type="checkbox" id="use-tts" checked>
                        <label for="use-tts"></label>
                    </div>
                </div>
                
                <div class="input-group">
                    <label for="voice-role1">Voz:</label>
                    <select id="voice-role1">
                        <option value="pt-BR-AntonioNeural">pt-BR-AntonioNeural (masculina)</option>
                        <option value="pt-BR-FranciscaNeural">pt-BR-FranciscaNeural (feminina)</option>
                        <option value="pt-BR-BrendaNeural">pt-BR-BrendaNeural (feminina)</option>
                        <option value="pt-BR-HumbertoNeural">pt-BR-HumbertoNeural (masculina)</option>
                    </select>
                </div>
            </div>
            
            <div class="audio-section" id="audio-section">
                <div class="input-group">
                    <label>
                        <input type="checkbox" id="use-audio">
                        Usar áudio personalizado
                    </label>
                    <div class="file-input">
                        <button id="select-audio-btn" disabled>Selecionar Áudio</button>
                        <span id="selected-audio-path">Nenhum áudio selecionado</span>
                    </div>
                </div>
            </div>
            
            <div class="progress-container">
                <div class="progress-bar">
                    <div class="progress" id="progress-bar" style="width: 0%"></div>
                </div>
                <div class="status" id="status-message">Pronto para iniciar</div>
            </div>
            
            <button class="start-btn" id="start-btn">Iniciar</button>
        </div>
    </div>
    <script src="./main.js" type="module"></script>
</body>
</html>
```

#### CSS (style.css)
```css
:root {
  --primary-color: #2c3e50;
  --secondary-color: #3498db;
  --accent-color: #e74c3c;
  --background-color: #f5f5f5;
  --text-color: #333;
  --border-color: #ddd;
  --success-color: #2ecc71;
}

* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
  font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
}

body {
  background-color: var(--background-color);
  color: var(--text-color);
  min-height: 100vh;
  display: flex;
  justify-content: center;
  align-items: center;
}

.container {
  width: 90%;
  max-width: 800px;
  background-color: white;
  border-radius: 8px;
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
  padding: 20px;
}

h1 {
  color: var(--primary-color);
  text-align: center;
  margin-bottom: 20px;
  font-size: 24px;
}

.main-content {
  display: flex;
  flex-direction: column;
  gap: 16px;
}

.input-group {
  display: flex;
  flex-direction: column;
  gap: 6px;
}

.input-group label {
  font-weight: 600;
  font-size: 14px;
  color: var(--primary-color);
}

.file-input {
  display: flex;
  align-items: center;
  gap: 10px;
}

.file-input button {
  background-color: var(--secondary-color);
  color: white;
  border: none;
  padding: 8px 12px;
  border-radius: 4px;
  cursor: pointer;
  font-size: 14px;
  transition: background-color 0.2s;
}

.file-input button:hover {
  background-color: #2980b9;
}

.file-input button:disabled {
  background-color: #95a5a6;
  cursor: not-allowed;
}

.file-input span {
  font-size: 14px;
  color: #666;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  flex: 1;
}

select {
  padding: 8px;
  border-radius: 4px;
  border: 1px solid var(--border-color);
  background-color: white;
  font-size: 14px;
}

.options-row {
  display: flex;
  gap: 16px;
}

.options-row .input-group {
  flex: 1;
}

.checkbox-wrapper {
  position: relative;
  display: inline-block;
}

.checkbox-wrapper input[type="checkbox"] {
  opacity: 0;
  position: absolute;
}

.checkbox-wrapper label {
  position: relative;
  display: inline-block;
  width: 40px;
  height: 20px;
  background-color: #ccc;
  border-radius: 20px;
  transition: all 0.3s;
  cursor: pointer;
}

.checkbox-wrapper label::after {
  content: '';
  position: absolute;
  width: 16px;
  height: 16px;
  border-radius: 50%;
  background-color: white;
  top: 2px;
  left: 2px;
  transition: all 0.3s;
}

.checkbox-wrapper input[type="checkbox"]:checked + label {
  background-color: var(--secondary-color);
}

.checkbox-wrapper input[type="checkbox"]:checked + label::after {
  transform: translateX(20px);
}

.audio-section {
  display: flex;
  flex-direction: column;
  gap: 10px;
  padding: 10px;
  border: 1px solid var(--border-color);
  border-radius: 4px;
  background-color: #f9f9f9;
}

.progress-container {
  margin-top: 20px;
}

.progress-bar {
  width: 100%;
  height: 20px;
  background-color: #ecf0f1;
  border-radius: 10px;
  overflow: hidden;
}

.progress {
  height: 100%;
  background-color: var(--secondary-color);
  width: 0%;
  transition: width 0.3s;
}

.status {
  margin-top: 5px;
  font-size: 14px;
  text-align: center;
  color: #666;
}

.start-btn {
  background-color: var(--accent-color);
  color: white;
  border: none;
  padding: 12px;
  border-radius: 4px;
  font-size: 16px;
  font-weight: 600;
  cursor: pointer;
  transition: background-color 0.2s;
  margin-top: 20px;
  width: 100%;
}

.start-btn:hover {
  background-color: #c0392b;
}

@media (max-width: 600px) {
  .options-row {
    flex-direction: column;
  }
  
  .container {
    width: 95%;
    padding: 15px;
  }
}
```

#### JavaScript (main.js)
```javascript
// Importações e configurações iniciais
import { invoke } from '@tauri-apps/api/tauri';
import { open, save } from '@tauri-apps/api/dialog';
import { appWindow } from '@tauri-apps/api/window';

// Elementos da interface
const selectVideoBtn = document.getElementById('select-video-btn');
const selectedVideoPath = document.getElementById('selected-video-path');
const saveToBtn = document.getElementById('save-to-btn');
const savePath = document.getElementById('save-path');
const useAudioCheckbox = document.getElementById('use-audio');
const selectAudioBtn = document.getElementById('select-audio-btn');
const selectedAudioPath = document.getElementById('selected-audio-path');
const startBtn = document.getElementById('start-btn');
const progressBar = document.getElementById('progress-bar');
const statusMessage = document.getElementById('status-message');

// Variáveis para armazenar caminhos
let videoPath = '';
let outputPath = '';
let audioPath = '';

// Inicialização
document.addEventListener('DOMContentLoaded', () => {
  // Desabilitar botão de iniciar até que um vídeo seja selecionado
  updateStartButtonState();
  
  // Configurar listener para eventos de progresso
  appWindow.listen('progress', (event) => {
    const { percent, message } = event.payload;
    updateProgress(percent);
    statusMessage.textContent = message;
  });
});

// Manipuladores de eventos
selectVideoBtn.addEventListener('click', async () => {
  try {
    const selected = await open({
      multiple: false,
      filters: [{
        name: 'Vídeo',
        extensions: ['mp4', 'avi', 'mkv', 'mov']
      }]
    });
    
    if (selected) {
      videoPath = Array.isArray(selected) ? selected[0] : selected;
      selectedVideoPath.textContent = videoPath;
      updateStartButtonState();
    }
  } catch (error) {
    console.error('Erro ao selecionar vídeo:', error);
    statusMessage.textContent = 'Erro ao selecionar vídeo';
  }
});

saveToBtn.addEventListener('click', async () => {
  try {
    const selected = await save({
      filters: [{
        name: 'Vídeo',
        extensions: ['mp4']
      }]
    });
    
    if (selected) {
      outputPath = selected;
      savePath.textContent = outputPath;
      updateStartButtonState();
    }
  } catch (error) {
    console.error('Erro ao selecionar destino:', error);
    statusMessage.textContent = 'Erro ao selecionar destino';
  }
});

useAudioCheckbox.addEventListener('change', () => {
  selectAudioBtn.disabled = !useAudioCheckbox.checked;
  if (!useAudioCheckbox.checked) {
    audioPath = '';
    selectedAudioPath.textContent = 'Nenhum áudio selecionado';
  }
});

selectAudioBtn.addEventListener('click', async () => {
  if (!useAudioCheckbox.checked) return;
  
  try {
    const selected = await open({
      multiple: false,
      filters: [{
        name: 'Áudio',
        extensions: ['mp3', 'wav', 'ogg']
      }]
    });
    
    if (selected) {
      audioPath = Array.isArray(selected) ? selected[0] : selected;
      selectedAudioPath.textContent = audioPath;
    }
  } catch (error) {
    console.error('Erro ao selecionar áudio:', error);
    statusMessage.textContent = 'Erro ao selecionar áudio';
  }
});

startBtn.addEventListener('click', async () => {
  if (!videoPath) {
    statusMessage.textContent = 'Selecione um vídeo primeiro';
    return;
  }
  
  // Desabilitar interface durante o processamento
  setInterfaceEnabled(false);
  
  try {
    statusMessage.textContent = 'Iniciando processamento...';
    updateProgress(5);
    
    // Chamar o backend Rust para iniciar o processo de dublagem
    const result = await invoke('start_dubbing', {
      config: {
        video_path: videoPath,
        output_path: outputPath || 'auto',
        original_language: document.getElementById('original-language').value,
        target_language: document.getElementById('target-language').value,
        use_tts: document.getElementById('use-tts').checked,
        voice_role1: document.getElementById('voice-role1').value,
        voice_role2: document.getElementById('voice-role1').value, // Usando a mesma voz para simplificar
        use_audio: useAudioCheckbox.checked,
        audio_path: audioPath || null
      }
    });
    
    statusMessage.textContent = `Processamento concluído com sucesso! Vídeo salvo em: ${result}`;
    updateProgress(100);
  } catch (error) {
    console.error('Erro durante o processamento:', error);
    statusMessage.textContent = `Erro: ${error}`;
    updateProgress(0);
  } finally {
    // Reabilitar interface após o processamento
    setInterfaceEnabled(true);
  }
});

// Funções auxiliares
function updateStartButtonState() {
  startBtn.disabled = !videoPath;
}

function setInterfaceEnabled(enabled) {
  const elements = [
    selectVideoBtn, saveToBtn, useAudioCheckbox, 
    selectAudioBtn, startBtn, 
    document.getElementById('original-language'),
    document.getElementById('target-language'),
    document.getElementById('use-tts'),
    document.getElementById('voice-role1')
  ];
  
  elements.forEach(el => {
    if (el) {
      el.disabled = !enabled;
    }
  });
  
  // Caso especial para o botão de áudio
  if (selectAudioBtn) {
    selectAudioBtn.disabled = !enabled || !useAudioCheckbox.checked;
  }
}

function updateProgress(percent) {
  progressBar.style.width = `${percent}%`;
}
```

### 3. Backend Rust (main.rs)

```rust
// Prevents additional console window on Windows in release, DO NOT REMOVE!!
#![cfg_attr(not(debug_assertions), windows_subsystem = "windows")]

use std::path::Path;
use std::process::Command;
use std::fs;
use std::io::Write;
use serde::{Deserialize, Serialize};
use anyhow::{Result, anyhow};
use reqwest::header::{HeaderMap, HeaderValue, AUTHORIZATION, CONTENT_TYPE};
use base64;
use tempfile::NamedTempFile;

// Configuração das chaves de API
const HUGGING_FACE_API_KEY: &str = "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";
const GEMINI_API_KEY: &str = "AIzaSyBlaM63VdIAua3P_kwyUpbMZAj9v2pWi7w";

#[derive(Debug, Serialize, Deserialize)]
struct DubbingConfig {
    video_path: String,
    output_path: String,
    original_language: String,
    target_language: String,
    use_tts: bool,
    voice_role1: String,
    voice_role2: String,
    use_audio: bool,
    audio_path: Option<String>,
}

#[derive(Debug, Serialize)]
struct ProgressUpdate {
    percent: u8,
    message: String,
}

// Estruturas para Hugging Face
#[derive(Debug, Serialize, Deserialize)]
struct HuggingFaceResponse {
    text: String,
}

// Estruturas para Gemini
#[derive(Debug, Serialize, Deserialize)]
struct GeminiRequest {
    contents: Vec<GeminiContent>,
}

#[derive(Debug, Serialize, Deserialize)]
struct GeminiContent {
    parts: Vec<GeminiPart>,
}

#[derive(Debug, Serialize, Deserialize)]
struct GeminiPart {
    text: String,
}

#[derive(Debug, Serialize, Deserialize)]
struct GeminiResponse {
    candidates: Vec<GeminiCandidate>,
}

#[derive(Debug, Serialize, Deserialize)]
struct GeminiCandidate {
    content: GeminiContent,
}

// Função principal para iniciar o processo de dublagem
#[tauri::command]
async fn start_dubbing(
    config: DubbingConfig,
    window: tauri::Window,
) -> Result<String, String> {
    // Validar caminhos
    if !Path::new(&config.video_path).exists() {
        return Err("Arquivo de vídeo não encontrado".to_string());
    }
    
    if config.use_audio && config.audio_path.is_some() {
        let audio_path = config.audio_path.as_ref().unwrap();
        if !Path::new(audio_path).exists() {
            return Err("Arquivo de áudio não encontrado".to_string());
        }
    }
    
    // Criar diretório temporário para arquivos intermediários
    let temp_dir = std::env::temp_dir().join("synthere_dub_temp");
    if !temp_dir.exists() {
        fs::create_dir_all(&temp_dir).map_err(|e| format!("Erro ao criar diretório temporário: {}", e))?;
    }
    
    // Extrair áudio do vídeo
    send_progress(&window, 10, "Extraindo áudio do vídeo...").await;
    let audio_file = temp_dir.join("audio_original.wav");
    extract_audio(&config.video_path, audio_file.to_str().unwrap())?;
    
    // Transcrever áudio original com Hugging Face
    send_progress(&window, 30, "Transcrevendo áudio original...").await;
    let transcription = transcribe_audio_with_huggingface(audio_file.to_str().unwrap())
        .await
        .map_err(|e| format!("Erro na transcrição: {}", e))?;
    
    // Traduzir para português com Gemini
    send_progress(&window, 50, "Traduzindo para português...").await;
    let translation = translate_with_gemini(&transcription)
        .await
        .map_err(|e| format!("Erro na tradução: {}", e))?;
    
    // Gerar áudio em português (TTS) com EDGE TTS
    send_progress(&window, 70, "Gerando áudio em português...").await;
    let dubbed_audio = temp_dir.join("audio_dubbed.wav");
    
    // Usar a voz selecionada pelo usuário (com pt-BR-AntonioNeural como padrão)
    let voice = if config.voice_role1.is_empty() {
        "pt-BR-AntonioNeural".to_string()
    } else {
        config.voice_role1.clone()
    };
    
    generate_audio_with_edge_tts(&translation, dubbed_audio.to_str().unwrap(), &voice)
        .await
        .map_err(|e| format!("Erro na síntese de voz: {}", e))?;
    
    // Finalizar vídeo dublado
    send_progress(&window, 90, "Finalizando vídeo dublado...").await;
    let output_path = if config.output_path == "auto" {
        let input_path = Path::new(&config.video_path);
        let file_stem = input_path.file_stem().unwrap().to_str().unwrap();
        let parent = input_path.parent().unwrap();
        parent.join(format!("{}_dublado.mp4", file_stem)).to_str().unwrap().to_string()
    } else {
        config.output_path
    };
    
    // Combinar vídeo original com áudio dublado
    merge_video_audio(&config.video_path, dubbed_audio.to_str().unwrap(), &output_path)?;
    
    // Limpar arquivos temporários
    // fs::remove_dir_all(temp_dir).map_err(|e| format!("Erro ao limpar arquivos temporários: {}", e))?;
    
    send_progress(&window, 100, "Processamento concluído com sucesso!").await;
    Ok(output_path)
}

// Função para extrair áudio de um vídeo usando ffmpeg
fn extract_audio(video_path: &str, output_audio: &str) -> Result<(), String> {
    let output = Command::new("ffmpeg")
        .args(&[
            "-i", video_path,
            "-vn",
            "-acodec", "pcm_s16le",
            "-ar", "44100",
            "-ac", "2",
            "-y",
            output_audio
        ])
        .output()
        .map_err(|e| format!("Erro ao executar ffmpeg: {}", e))?;
    
    if !output.status.success() {
        let error = String::from_utf8_lossy(&output.stderr);
        return Err(format!("Erro ao extrair áudio: {}", error));
    }
    
    Ok(())
}

// Função para combinar vídeo e áudio usando ffmpeg
fn merge_video_audio(video_path: &str, audio_path: &str, output_path: &str) -> Result<(), String> {
    let output = Command::new("ffmpeg")
        .args(&[
            "-i", video_path,
            "-i", audio_path,
            "-c:v", "copy",
            "-c:a", "aac",
            "-map", "0:v:0",
            "-map", "1:a:0",
            "-shortest",
            "-y",
            output_path
        ])
        .output()
        .map_err(|e| format!("Erro ao executar ffmpeg: {}", e))?;
    
    if !output.status.success() {
        let error = String::from_utf8_lossy(&output.stderr);
        return Err(format!("Erro ao combinar vídeo e áudio: {}", error));
    }
    
    Ok(())
}

// Função para enviar atualizações de progresso para o frontend
async fn send_progress(window: &tauri::Window, percent: u8, message: &str) {
    let _ = window.emit("progress", ProgressUpdate {
        percent,
        message: message.to_string(),
    });
}

// Função para transcrever áudio com Hugging Face
async fn transcribe_audio_with_huggingface(audio_path: &str) -> Result<String> {
    let client = reqwest::Client::new();
    
    // Ler o arquivo de áudio
    let audio_data = fs::read(audio_path)?;
    
    // Codificar o áudio em base64
    let audio_base64 = base64::encode(&audio_data);
    
    let mut headers = HeaderMap::new();
    headers.insert(AUTHORIZATION, HeaderValue::from_str(&format!("Bearer {}", HUGGING_FACE_API_KEY))?);
    headers.insert(CONTENT_TYPE, HeaderValue::from_static("application/json"));
    
    // Criar o payload para a API do Hugging Face (usando o modelo Whisper)
    let payload = serde_json::json!({
        "inputs": audio_base64,
        "model": "openai/whisper-large-v3",
        "parameters": {
            "language": "en"
        }
    });
    
    // Enviar a requisição para a API do Hugging Face
    let response = client.post("https://api-inference.huggingface.co/models/openai/whisper-large-v3")
        .headers(headers)
        .json(&payload)
        .send()
        .await?;
    
    if !response.status().is_success() {
        return Err(anyhow!("Erro na transcrição: {}", response.text().await?));
    }
    
    let result: HuggingFaceResponse = response.json().await?;
    
    Ok(result.text)
}

// Função para traduzir texto com Gemini
async fn translate_with_gemini(text: &str) -> Result<String> {
    let client = reqwest::Client::new();
    
    let prompt = format!(
        "Traduza o seguinte texto do inglês para o português brasileiro, mantendo o mesmo tom e estilo. Não adicione nenhum comentário ou explicação, apenas retorne o texto traduzido:\n\n{}",
        text
    );
    
    let request = GeminiRequest {
        contents: vec![
            GeminiContent {
                parts: vec![
                    GeminiPart {
                        text: prompt,
                    }
                ]
            }
        ]
    };
    
    let response = client.post(&format!(
        "https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key={}",
        GEMINI_API_KEY
    ))
    .json(&request)
    .send()
    .await?;
    
    if !response.status().is_success() {
        return Err(anyhow!("Erro na tradução: {}", response.text().await?));
    }
    
    let gemini_response: GeminiResponse = response.json().await?;
    
    if gemini_response.candidates.is_empty() {
        return Err(anyhow!("Nenhuma tradução retornada"));
    }
    
    let translated_text = gemini_response.candidates[0].content.parts.get(0)
        .ok_or_else(|| anyhow!("Resposta vazia"))?
        .text.clone();
    
    Ok(translated_text)
}

// Função para gerar áudio com EDGE TTS
async fn generate_audio_with_edge_tts(text: &str, output_path: &str, voice: &str) -> Result<()> {
    // Usando o comando edge-tts via shell
    // Alternativa: implementar a comunicação direta com o serviço EDGE TTS
    
    // Criar arquivo temporário para o texto
    let mut temp_file = NamedTempFile::new()?;
    writeln!(temp_file, "{}", text)?;
    
    let output = Command::new("npx")
        .args(&[
            "edge-tts",
            "--voice", voice,
            "--file", temp_file.path().to_str().unwrap(),
            "--write-media", output_path
        ])
        .output()
        .map_err(|e| anyhow!("Erro ao executar edge-tts: {}", e))?;
    
    if !output.status.success() {
        let error = String::from_utf8_lossy(&output.stderr);
        return Err(anyhow!("Erro na síntese de voz: {}", error));
    }
    
    Ok(())
}

// Função para obter a lista de vozes disponíveis
#[tauri::command]
fn get_available_voices() -> Vec<String> {
    vec![
        "pt-BR-AntonioNeural".to_string(),
        "pt-BR-FranciscaNeural".to_string(),
        "pt-BR-BrendaNeural".to_string(),
        "pt-BR-HumbertoNeural".to_string(),
    ]
}

fn main() {
    tauri::Builder::default()
        .invoke_handler(tauri::generate_handler![start_dubbing, get_available_voices])
        .run(tauri::generate_context!())
        .expect("erro ao executar aplicação tauri");
}
```

### 4. Configuração do Tauri (Cargo.toml)

```toml
[package]
name = "synthere_dub"
version = "0.1.0"
description = "Software de dublagem de vídeos do inglês para o português brasileiro"
authors = ["Desenvolvedor"]
license = ""
repository = ""
edition = "2021"

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[build-dependencies]
tauri-build = { version = "1.5", features = [] }

[dependencies]
tauri = { version = "1.5", features = ["dialog-all", "shell-open"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
reqwest = { version = "0.11", features = ["json", "multipart"] }
tokio = { version = "1", features = ["full"] }
base64 = "0.13"
tempfile = "3.2"
anyhow = "1.0"
thiserror = "1.0"

[features]
# this feature is used for production builds or when `devPath` points to the filesystem
# DO NOT REMOVE!!
custom-protocol = ["tauri/custom-protocol"]
```

### 5. Configuração do Vite (vite.config.js)

```javascript
import { defineConfig } from 'vite';

export default defineConfig({
  // Configuração para o servidor de desenvolvimento
  server: {
    port: 1420,
    strictPort: true,
  },
  // Configuração para o build de produção
  build: {
    outDir: 'dist',
    target: 'esnext',
    minify: 'esbuild',
  },
});
```

## Compilação e Execução

Para compilar o projeto no Replit:

1. Configure o ambiente:
```bash
apt-get update
apt-get install -y build-essential pkg-config libssl-dev libgtk-3-dev libwebkit2gtk-4.0-dev libappindicator3-dev librsvg2-dev patchelf ffmpeg
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y
source "$HOME/.cargo/env"
npm install -g edge-tts
```

2. Compile o projeto:
```bash
cd synthere_dub
npm install
cargo tauri build
```

3. O executável final estará disponível em:
```
synthere_dub/src-tauri/target/release/synthere_dub
```

## Notas Finais

- A interface gráfica foi projetada para ser similar à imagem de referência fornecida, com todos os elementos em português brasileiro.
- O fluxo de trabalho automatizado permite a dublagem de vídeos do inglês para o português brasileiro com poucos cliques.
- As APIs de transcrição (Hugging Face), tradução (Gemini) e síntese de voz (EDGE TTS) foram integradas conforme solicitado.
- O seletor de vozes permite alternar entre vozes masculinas e femininas, com pt-BR-AntonioNeural como padrão.
- O executável final é um arquivo único e autossuficiente que pode ser distribuído facilmente.

Este prompt fornece todas as instruções necessárias para criar o SynthereDub PT-BR no Replit, desde a configuração do ambiente até a compilação final, seguindo fielmente as especificações e referências fornecidas.